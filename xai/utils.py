"""
XAI modÃ¼lÃ¼ iÃ§in yardÄ±mcÄ± fonksiyonlar: gÃ¶rsel I/O, overlay, path utilities.
"""
import os
import json
import cv2
import numpy as np
import torch
from pathlib import Path
from typing import Dict, List, Tuple, Optional


def ensure_output_dir(output_dir: str) -> Path:
    """Ã‡Ä±ktÄ± klasÃ¶rÃ¼nÃ¼ oluÅŸturur ve Path dÃ¶ndÃ¼rÃ¼r."""
    out_path = Path(output_dir)
    out_path.mkdir(parents=True, exist_ok=True)
    return out_path


def clean_output_dir(output_dir: str) -> None:
    """
    Ã‡Ä±ktÄ± klasÃ¶rÃ¼ndeki tÃ¼m dosyalarÄ± siler.
    
    Args:
        output_dir: Temizlenecek Ã§Ä±ktÄ± klasÃ¶rÃ¼ yolu
    """
    out_path = Path(output_dir)
    if not out_path.exists():
        return
    
    # KlasÃ¶rdeki tÃ¼m dosyalarÄ± sil
    for file_path in out_path.iterdir():
        if file_path.is_file():
            try:
                file_path.unlink()
                print(f"ðŸ—‘ï¸  Silindi: {file_path.name}")
            except Exception as e:
                print(f"âš ï¸  Silinemedi {file_path.name}: {e}")
    
    print(f"âœ… Ã‡Ä±ktÄ± klasÃ¶rÃ¼ temizlendi: {out_path}")


def load_image(image_path: str) -> np.ndarray:
    """
    GÃ¶rÃ¼ntÃ¼yÃ¼ BGR formatÄ±nda yÃ¼kler.
    
    Args:
        image_path: GÃ¶rÃ¼ntÃ¼ dosya yolu
        
    Returns:
        BGR gÃ¶rÃ¼ntÃ¼ (numpy array)
        
    Raises:
        FileNotFoundError: GÃ¶rÃ¼ntÃ¼ bulunamazsa
    """
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"GÃ¶rÃ¼ntÃ¼ bulunamadÄ±: {image_path}")
    return img


def preprocess_image_for_yolo(
    bgr_img: np.ndarray, 
    target_size: int = 640
) -> Tuple[np.ndarray, torch.Tensor]:
    """
    GÃ¶rÃ¼ntÃ¼yÃ¼ YOLO iÃ§in Ã¶n iÅŸleme yapar.
    
    Args:
        bgr_img: BGR formatÄ±nda gÃ¶rÃ¼ntÃ¼
        target_size: Hedef boyut (kare)
        
    Returns:
        (orijinal_boyutlu_rgb, tensor) tuple
    """
    rgb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
    h, w = rgb.shape[:2]
    
    # Resize
    img_resized = cv2.resize(rgb, (target_size, target_size))
    img_resized = img_resized.astype(np.float32) / 255.0
    img_resized = np.transpose(img_resized, (2, 0, 1))  # CHW
    
    img_tensor = torch.from_numpy(img_resized).unsqueeze(0)  # [1, C, H, W]
    
    return rgb, img_tensor


def enhance_heatmap(
    cam: np.ndarray,
    percentile_low: float = 80.0,
    percentile_high: float = 99.5,
    top_percent: float = 25.0,
    gaussian_blur: int = 5
) -> np.ndarray:
    """
    Heatmap'i iyileÅŸtirir: percentile clipping, threshold, Gaussian blur.
    
    Args:
        cam: Normalize edilmiÅŸ CAM (0-1 arasÄ±, [H, W])
        percentile_low: Alt percentile clipping (varsayÄ±lan: 80)
        percentile_high: Ãœst percentile clipping (varsayÄ±lan: 99.5)
        top_percent: Sadece en yÃ¼ksek %X aktivasyonu tut (varsayÄ±lan: 25)
        gaussian_blur: Gaussian blur kernel boyutu (varsayÄ±lan: 5, 0 ise blur yok)
        
    Returns:
        Ä°yileÅŸtirilmiÅŸ CAM (0-1 arasÄ±)
    """
    # NaN ve inf deÄŸerlerini temizle
    cam_clean = np.nan_to_num(cam, nan=0.0, posinf=1.0, neginf=0.0)
    cam_clean = np.clip(cam_clean, 0, 1)
    
    # Percentile clipping (daha agresif normalizasyon)
    if cam_clean.max() > cam_clean.min():
        p_low = np.percentile(cam_clean, percentile_low)
        p_high = np.percentile(cam_clean, percentile_high)
        
        # Clipping uygula
        cam_clipped = np.clip(cam_clean, p_low, p_high)
        # Min-max normalize et
        if p_high > p_low:
            cam_clipped = (cam_clipped - p_low) / (p_high - p_low + 1e-8)
        else:
            cam_clipped = cam_clean
    else:
        cam_clipped = cam_clean
    
    # Top %X threshold (dÃ¼ÅŸÃ¼k aktivasyonlarÄ± bastÄ±r)
    if top_percent > 0 and cam_clipped.max() > 0:
        threshold = np.percentile(cam_clipped, 100 - top_percent)
        # Threshold altÄ±ndaki deÄŸerleri zayÄ±flat
        cam_clipped = np.where(
            cam_clipped >= threshold,
            cam_clipped,
            cam_clipped * 0.1  # Ã‡ok dÃ¼ÅŸÃ¼k aktivasyonlarÄ± neredeyse sÄ±fÄ±rla
        )
        # Yeniden normalize et
        if cam_clipped.max() > 0:
            cam_clipped = cam_clipped / cam_clipped.max()
    
    # Gaussian blur ile gÃ¼rÃ¼ltÃ¼yÃ¼ azalt
    if gaussian_blur > 0 and gaussian_blur % 2 == 1:
        cam_clipped = cv2.GaussianBlur(
            cam_clipped,
            (gaussian_blur, gaussian_blur),
            0
        )
        # Blur sonrasÄ± normalize et
        if cam_clipped.max() > 0:
            cam_clipped = cam_clipped / cam_clipped.max()
    
    return np.clip(cam_clipped, 0, 1)


def overlay_heatmap(
    bgr_img: np.ndarray, 
    cam: np.ndarray, 
    alpha: float = 0.6
) -> np.ndarray:
    """
    Heatmap'i gÃ¶rÃ¼ntÃ¼ Ã¼zerine bindirir (GERÄ°YE DÃ–NÃœK UYUMLULUK Ä°Ã‡Ä°N KORUNDU).
    Yeni iyileÅŸtirilmiÅŸ versiyonlar iÃ§in overlay_heatmap_full veya overlay_heatmap_bbox kullanÄ±n.
    
    Args:
        bgr_img: BGR formatÄ±nda orijinal gÃ¶rÃ¼ntÃ¼
        cam: Normalize edilmiÅŸ CAM (0-1 arasÄ±, [H, W])
        alpha: Overlay ÅŸeffaflÄ±ÄŸÄ± (0-1)
        
    Returns:
        Overlay edilmiÅŸ BGR gÃ¶rÃ¼ntÃ¼
    """
    h, w = bgr_img.shape[:2]
    
    # CAM'i gÃ¶rÃ¼ntÃ¼ boyutuna Ã¶lÃ§ekle (yÃ¼ksek kaliteli interpolasyon)
    cam_resized = cv2.resize(cam, (w, h), interpolation=cv2.INTER_CUBIC)
    
    # Ä°yileÅŸtirilmiÅŸ heatmap iÅŸleme
    cam_enhanced = enhance_heatmap(cam_resized, percentile_low=80.0, percentile_high=99.5, top_percent=25.0, gaussian_blur=5)
    
    # Normalize et (0-255 arasÄ±)
    cam_enhanced = (np.clip(cam_enhanced, 0, 1) * 255).astype(np.uint8)
    
    # TURBO colormap uygula (JET yerine, daha algÄ±sal olarak net)
    heatmap = cv2.applyColorMap(cam_enhanced, cv2.COLORMAP_TURBO)
    
    # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlara Ã§evir (heatmap daha belirgin olsun)
    gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)
    gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    
    # Overlay: gri gÃ¶rÃ¼ntÃ¼ + renkli heatmap
    out = cv2.addWeighted(gray_bgr, 1 - alpha, heatmap, alpha, 0)
    
    return out


def overlay_heatmap_full(
    bgr_img: np.ndarray,
    cam: np.ndarray,
    boxes: Optional[List[Tuple[int, int, int, int]]] = None,
    alpha_base: float = 0.4,
    alpha_bbox: float = 0.7,
    bbox_focus_strength: float = 0.3
) -> np.ndarray:
    """
    Tam gÃ¶rÃ¼ntÃ¼ Ã¼zerine kontrollÃ¼ heatmap overlay (bbox odaklÄ±).
    
    Args:
        bgr_img: BGR formatÄ±nda orijinal gÃ¶rÃ¼ntÃ¼
        cam: Normalize edilmiÅŸ CAM (0-1 arasÄ±, [H, W])
        boxes: Bbox listesi [(x1, y1, x2, y2), ...] (opsiyonel)
        alpha_base: Arka plan iÃ§in alpha (varsayÄ±lan: 0.4)
        alpha_bbox: Bbox iÃ§i iÃ§in alpha (varsayÄ±lan: 0.7)
        bbox_focus_strength: Bbox dÄ±ÅŸÄ± heatmap zayÄ±flatma gÃ¼cÃ¼ (0-1, varsayÄ±lan: 0.3)
        
    Returns:
        Overlay edilmiÅŸ BGR gÃ¶rÃ¼ntÃ¼
    """
    h, w = bgr_img.shape[:2]
    
    # CAM'i gÃ¶rÃ¼ntÃ¼ boyutuna Ã¶lÃ§ekle
    cam_resized = cv2.resize(cam, (w, h), interpolation=cv2.INTER_CUBIC)
    
    # Ä°yileÅŸtirilmiÅŸ heatmap iÅŸleme
    cam_enhanced = enhance_heatmap(cam_resized, percentile_low=80.0, percentile_high=99.5, top_percent=25.0, gaussian_blur=5)
    
    # Bbox odaklÄ± zayÄ±flatma (bbox dÄ±ÅŸÄ±ndaki heatmap'i bastÄ±r)
    if boxes and len(boxes) > 0:
        # Bbox maskesi oluÅŸtur
        bbox_mask = np.zeros((h, w), dtype=np.float32)
        for (x1, y1, x2, y2) in boxes:
            # Bbox iÃ§ini 1.0, dÄ±ÅŸÄ±nÄ± 0.0 yap
            bbox_mask[y1:y2, x1:x2] = 1.0
        
        # Bbox iÃ§i ve dÄ±ÅŸÄ± iÃ§in farklÄ± aÄŸÄ±rlÄ±klar
        # Bbox iÃ§i: tam gÃ¼Ã§, bbox dÄ±ÅŸÄ±: zayÄ±flatÄ±lmÄ±ÅŸ
        cam_focused = cam_enhanced.copy()
        cam_focused = cam_focused * (bbox_mask + (1 - bbox_mask) * bbox_focus_strength)
        
        # Dinamik alpha: bbox iÃ§i yÃ¼ksek, dÄ±ÅŸÄ± dÃ¼ÅŸÃ¼k
        alpha_map = np.ones((h, w), dtype=np.float32) * alpha_base
        alpha_map = alpha_map + bbox_mask * (alpha_bbox - alpha_base)
    else:
        cam_focused = cam_enhanced
        alpha_map = np.ones((h, w), dtype=np.float32) * alpha_base
    
    # Normalize et (0-255 arasÄ±)
    cam_enhanced = (np.clip(cam_focused, 0, 1) * 255).astype(np.uint8)
    
    # TURBO colormap uygula
    heatmap = cv2.applyColorMap(cam_enhanced, cv2.COLORMAP_TURBO)
    
    # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlara Ã§evir
    gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)
    gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    
    # Dinamik alpha blending
    alpha_3d = np.stack([alpha_map] * 3, axis=2)  # [H, W, 3]
    out = (gray_bgr.astype(np.float32) * (1 - alpha_3d) + 
           heatmap.astype(np.float32) * alpha_3d).astype(np.uint8)
    
    return out


def overlay_heatmap_bbox(
    bgr_img: np.ndarray,
    cam: np.ndarray,
    bbox: Tuple[int, int, int, int],
    padding: int = 20,
    alpha: float = 0.75
) -> np.ndarray:
    """
    Sadece bbox crop Ã¼zerine yÃ¼ksek kontrastlÄ± heatmap overlay.
    
    Args:
        bgr_img: BGR formatÄ±nda orijinal gÃ¶rÃ¼ntÃ¼
        cam: Normalize edilmiÅŸ CAM (0-1 arasÄ±, [H, W])
        bbox: (x1, y1, x2, y2) bbox koordinatlarÄ±
        padding: Bbox etrafÄ±na eklenecek padding (piksel, varsayÄ±lan: 20)
        alpha: Overlay ÅŸeffaflÄ±ÄŸÄ± (varsayÄ±lan: 0.75, yÃ¼ksek kontrast iÃ§in)
        
    Returns:
        Bbox crop + overlay edilmiÅŸ BGR gÃ¶rÃ¼ntÃ¼
    """
    h, w = bgr_img.shape[:2]
    x1, y1, x2, y2 = bbox
    
    # Padding ekle (gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±rlarÄ± iÃ§inde)
    x1_crop = max(0, x1 - padding)
    y1_crop = max(0, y1 - padding)
    x2_crop = min(w, x2 + padding)
    y2_crop = min(h, y2 + padding)
    
    # Crop gÃ¶rÃ¼ntÃ¼
    img_crop = bgr_img[y1_crop:y2_crop, x1_crop:x2_crop].copy()
    h_crop, w_crop = img_crop.shape[:2]
    
    if h_crop == 0 or w_crop == 0:
        return bgr_img  # GeÃ§ersiz crop
    
    # CAM'i crop boyutuna Ã¶lÃ§ekle
    cam_resized = cv2.resize(cam, (w, h), interpolation=cv2.INTER_CUBIC)
    cam_crop = cam_resized[y1_crop:y2_crop, x1_crop:x2_crop]
    
    # Ä°yileÅŸtirilmiÅŸ heatmap iÅŸleme (daha agresif parametreler)
    cam_enhanced = enhance_heatmap(
        cam_crop,
        percentile_low=75.0,  # Daha agresif
        percentile_high=99.8,
        top_percent=20.0,  # Sadece top %20
        gaussian_blur=3  # Daha az blur (daha keskin)
    )
    
    # Normalize et (0-255 arasÄ±)
    cam_enhanced = (np.clip(cam_enhanced, 0, 1) * 255).astype(np.uint8)
    
    # HOT colormap uygula (bbox crop iÃ§in daha kontrastlÄ±)
    heatmap = cv2.applyColorMap(cam_enhanced, cv2.COLORMAP_HOT)
    
    # Orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ gri tonlara Ã§evir
    gray = cv2.cvtColor(img_crop, cv2.COLOR_BGR2GRAY)
    gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)
    
    # YÃ¼ksek kontrastlÄ± overlay
    out_crop = cv2.addWeighted(gray_bgr, 1 - alpha, heatmap, alpha, 0)
    
    # Orijinal gÃ¶rÃ¼ntÃ¼ye geri yerleÅŸtir
    out = bgr_img.copy()
    out[y1_crop:y2_crop, x1_crop:x2_crop] = out_crop
    
    return out


def draw_detections(
    img: np.ndarray,
    boxes: List[Tuple[int, int, int, int]],
    confidences: List[float],
    class_names: List[str],
    color: Tuple[int, int, int] = (0, 255, 0),
    line_thickness: int = 2
) -> np.ndarray:
    """
    Tespit edilen nesneleri gÃ¶rÃ¼ntÃ¼ Ã¼zerine Ã§izer.
    
    Args:
        img: BGR gÃ¶rÃ¼ntÃ¼
        boxes: [(x1, y1, x2, y2), ...] listesi
        confidences: Confidence deÄŸerleri listesi
        class_names: SÄ±nÄ±f isimleri listesi
        color: Bbox rengi (BGR)
        line_thickness: Ã‡izgi kalÄ±nlÄ±ÄŸÄ±
        
    Returns:
        Ã‡izilmiÅŸ gÃ¶rÃ¼ntÃ¼
    """
    img_copy = img.copy()
    for (x1, y1, x2, y2), conf, cls_name in zip(boxes, confidences, class_names):
        cv2.rectangle(img_copy, (x1, y1), (x2, y2), color, line_thickness)
        label = f"{cls_name} {conf:.2f}"
        (label_w, label_h), _ = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )
        cv2.rectangle(
            img_copy,
            (x1, y1 - label_h - 10),
            (x1 + label_w, y1),
            color,
            -1
        )
        cv2.putText(
            img_copy,
            label,
            (x1, y1 - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 255),
            2,
            cv2.LINE_AA
        )
    return img_copy


def save_heatmap_only(
    cam: np.ndarray,
    output_path: str,
    original_shape: Tuple[int, int]
) -> None:
    """
    Sadece heatmap'i kaydeder (bbox olmadan).
    Ä°yileÅŸtirilmiÅŸ gÃ¶rselleÅŸtirme ile.
    
    Args:
        cam: Normalize edilmiÅŸ CAM (0-1 arasÄ±)
        output_path: Ã‡Ä±ktÄ± dosya yolu
        original_shape: (height, width) orijinal gÃ¶rÃ¼ntÃ¼ boyutu
    """
    h, w = original_shape
    cam_resized = cv2.resize(cam, (w, h), interpolation=cv2.INTER_CUBIC)
    
    # Ä°yileÅŸtirilmiÅŸ heatmap iÅŸleme
    cam_enhanced = enhance_heatmap(cam_resized, percentile_low=80.0, percentile_high=99.5, top_percent=25.0, gaussian_blur=5)
    
    # Normalize et
    cam_enhanced = (np.clip(cam_enhanced, 0, 1) * 255).astype(np.uint8)
    
    # TURBO colormap uygula
    heatmap = cv2.applyColorMap(cam_enhanced, cv2.COLORMAP_TURBO)
    cv2.imwrite(output_path, heatmap)


def save_metadata(
    output_path: str,
    detections: List[Dict],
    conf_threshold: float
) -> None:
    """
    Tespit metadata'sÄ±nÄ± JSON olarak kaydeder.
    
    Args:
        output_path: Ã‡Ä±ktÄ± JSON dosya yolu
        detections: Tespit bilgileri listesi
        conf_threshold: KullanÄ±lan confidence threshold
    """
    metadata = {
        "conf_threshold": conf_threshold,
        "num_detections": len(detections),
        "detections": detections
    }
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)


def format_detection_info(
    x1: int, y1: int, x2: int, y2: int,
    conf: float, cls: int, cls_name: str
) -> Dict:
    """Tespit bilgisini dictionary formatÄ±na Ã§evirir."""
    return {
        "bbox": [int(x1), int(y1), int(x2), int(y2)],
        "confidence": float(conf),
        "class_id": int(cls),
        "class_name": str(cls_name)
    }

